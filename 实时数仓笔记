---
title : 实时数仓笔记

---

# 一.ODS层

采集到Kafka的topic_log和topic_db主题的数据即为实时数仓的ODS层，这一层的作用是对数据做原样展示和备份。



# 二.DIM层

**设计要点** ：

1. DIM层的设计依据是维度建模理论，该层存储维度模型的维度表。
2. DIM层的数据存储在Hbase表中。DIM层表是用于维度关联的，要通过主键去获取相关维度信息，这种场景下K-V类型数据库的效率很高。而Redis的数据常驻内存，会给内存造成较大的压力，因而选用Hbase存储维度数据。

**配置表：**

* 为了让程序知道流中的哪些数据是维度数据，选择在MySQL中构建一张配置表，通过Flink CDC将配置表信息读取到程序中。

**主要任务：**

1. **接收Kafka数据，过滤空值数据：**对Maxwell抓取的数据进行ETL。
2. **动态拆分维度表功能：**由于Maxwell是把全部数据统一写入一个topic中，这样不利于日后的数据处理。需要把各个维度表拆开处理。MySQL对于配置数据初始化和维度管理，使用Flink CDC读取配置信息表，将配置流作为广播流与主流进行连接。
3. **把流中的数据保存到对应的维度表**。

**代码要点：**

* 读取Kafka主题数据，过滤掉非JSON数据，保留新增、变化以及初始化数据，并将数据转为JSON格式。



# 三.DWD层

**设计要点：**依据维度建模理论，该层存储维度模型的事实表。



## 1.流量域未经加工的事物事实表

* **数据清洗：**将JSON对象解析失败的数据发送到侧输出流，写入Kafka脏数据主题。
* **新老访客状态标记修复：**使用状态编程，为每个mid维护一个键控状态，记录首次访问日期。
* **利用侧输出流实现数据拆分。**



## 2. 流量域独立访客事物事实表

* **过滤last_page_id不为null的数据：**独立访客数据对应的页面必然是会话起始页面。减小数据量，提升计算效率。
* **筛选独立访客记录：**运用Flink状态编程，为每个mid维护一个键控状态，记录末次登录日期。如果末次登录日期为null或者不是今日，则本次访问是该mid当日首次访问，保留数据，将末次登录日期更新为当日。否则丢弃数据。
* **状态存货时间设置：**设置状态的TTL为1天，更新模式为OnCreateAndWrite，表示在创建和更新状态时重置状态存活时间。



## 3. 流量域用户跳出事物事实表

* **筛选策略：**跳出是指会话中只有一个页面的访问行为。使用Flink CEP进行模式匹配。
* **实现步骤：**
  * 按照mid分组。
  * 定义CEP匹配规则
    1. 判定last_page_id是否为null。
    2. 判定当前数据的last_page_id是否为null。
    3. 超时时间内规则1被满足，未等到第二条数据则会被判定为超时数据。



## 4.交易域加购事物事实表

* **维度关联（维度退化）实现策略分析：**全部使用Flink SQL实现，字典表数据存储在MySQL的业务数据库中，要做维度退化，将数据从MySQL中提取封装成Flink SQL表，用Flink的JDBC SQL Connector实现需求。
* **知识储备**
  1. **JDBC SQL Connector：**让Flink程序从拥有JDBC驱动的任意关系型数据库中读取数据或将数据写入数据库。
  2. **Lookup Cache：**JDBC连接器可以作为时态表关联中的查询数据源（又称维表），目前仅支持同步查询。
     * 默认情况下，查询缓存（Lookup Cache）未被启用，需要设置 **<u>lookup.cache.max-rows</u>** 和 <u>**lookup.cache.ttl**</u> 参数来启用此功能。
     * Lookup 缓存是用来提升有 JDBC 连接器参与的时态关联性能的。默认情况下，缓存未启用，所有的请求会被发送到外部数据库。
     * 当缓存启用时，每个进程（即 TaskManager）维护一份缓存。收到请求时，Flink 会先查询缓存，如果缓存未命中才会向外部数据库发送请求，并用查询结果更新缓存。
     * 如果缓存中的记录条数达到了 lookup.cache.max-rows 规定的最大行数时将清除存活时间最久的记录。如果缓存中的记录存活时间超过了 lookup.cache.ttl 规定的最大存活时间，同样会被清除。
     * 缓存中的记录未必是最新的，可以将 lookup.cache.ttl 设置为一个更小的值来获得时效性更好的数据，但这样做会增加发送到数据库的请求数量。所以需要在吞吐量和正确性之间寻求平衡。
  3. **Lookup Join：**
     * Lookup Join <u>**通常在 Flink SQL 表和外部系统查询结果关联时使用**</u>。这种关联要求一张表（主表）有处理时间字段，而另一张表（维表）由 Lookup 连接器生成。
     * Lookup Join 做的是维度关联，而维度数据是有时效性的，那么我们就需要一个时间字段来对数据的版本进行标识。因此，Flink 要求我们提供处理时间用作版本字段。
* **执行步骤**
  1. **设置表状态的TTL：**
     - 表之间做普通关联时，底层会将两张表的数据维护到状态中，默认情况下状态永远不会清空，这样会对内存造成极大的压力。
     - 表状态的 ttl 是 Idle（空闲，即状态未被更新）状态被保留的最短时间，假设 ttl 为 10s，若状态中的数据在 10s 内未被更新，则未来的某个时间会被清除（故而 ttl 是最短存活时间）。ttl 默认值为 0，表示永远不会清空状态。
     - 字典表是作为维度表被 Flink 程序维护的，<u>字典表与加购表不存在业务上的滞后关系，而 look up join 是由主表触发的，即主表数据到来后去 look up 表中查询对应的维度信息，如果缓存未命中就要从外部介质中获取数据，这就要求主表数据在状态中等待一段时间，此处将 ttl 设置为 5s，主表数据会在状态中保存至少 5s。</u>而 look up 表的 cache 是由建表时指定的相关参数决定的，与此处的 ttl 无关。
  2. **读取购物车表数据。**
  3. **建立Mysql-LookUp字典表。**
  4. **关联购物车表和字典表，维度退化。**



## 5.交易域订单预处理表

**主要任务：**

* 订单明细表和取消订单明细表的数据来源、表结构都相同，差别只在业务过程和过滤条件，为了减少重复计算，将两张表公共的关联过程提取出来，形成订单预处理表。
* 关联订单明细表、订单表、订单明细活动关联表、订单明细优惠劵关联表四张事实业务表和字典表（维度业务表）形成订单预处理表，写入Kafka对应主题。

**思路分析：**

* 知识储备
  1. **left join实现过程：**假设 A 表作为主表与 B 表做等值左外联。当 A 表数据进入算子，而 B 表数据未至时会先生成一条 B 表字段均为 null 的关联数据ab1，其标记为 +I。其后，B 表数据到来，会先将之前的数据撤回，即生成一条与 ab1 内容相同，但标记为 -D 的数据，再生成一条关联后的数据，标记为 +I。<u>**这样生成的动态表对应的流称之为回撤流。**</u>
  2. **Kafka SQL Connector：**分为 <u>Kafka SQL Connector</u> 和 <u>Upsert Kafka SQL Connector</u>。
     - **功能：**
       1. Upsert Kafka Connector支持以 upsert 方式从 Kafka topic 中读写数据。
       2. Kafka Connector支持从 Kafka topic 中读写数据。
     - **区别：**
       1. **建表语句的主键：**Kafka Connector要求表不能有主键，如果设置了主键就会报错。Upsert Kafka Connector要求表必须有主键，如果没有设置主键就会报错。如果没有not enforced就会报错，表示不对来往数据做约束校验，Flink并是不数据的主人，只支持not enforced。
       2. **对表中数据操作类型的要求：**Kafka Connector不能消费带有Upsert/Delete操作类型数据的表，如left join生成的动态表。Upsert Kafka Connector 将Insert/Update_After数据作为正常的Kafka消息写入，并将Delete数据以value为空的Kafka消息写入（表示对应key的消息被删除）。Flink将根据主键列的值对数据进行分区，因此同一主键的更新/删除消息将落在同一分区，从而保证同一主键的消息有序。
* **执行步骤：**
  1. **设置TTL：**订单明细表、订单表、订单明细优惠券管理表和订单明细活动关联表不存在业务上的滞后问题，只考虑可能的数据乱序即可，此处将 ttl 设置为 5s。**<u>（分区处理后数据乱序）</u>**
  2. **从Kafka topic_db主题读取业务数据：**要调用 PROCTIME() 函数获取系统时间作为与字典表做 Lookup Join 的处理时间字段。
  3. **筛选订单明细表数据：**应尽可能保证事实表的粒度为最细粒度，在下单业务过程中，最细粒度的事件为一个订单的一个 SKU 的下单操作，订单明细表的粒度与最细粒度相同，将其作为**主表**。
  4. **筛选订单表数据：**通过该表获取 user_id 和 province_id。保留 type 字段和 old 字段用于筛选订单明细数据和取消订单明细数据。
  5. **筛选订单明细活动关联表数据：**通过该表获取活动 id 和活动规则 id。
  6. **筛选订单明细优惠券关联表数据：**通过该表获取优惠券 id。
  7. **建立Mysql-Lookup字典表：**通过字典表获取订单来源类型名称。
  8. **关联上述五张表获得订单宽表，写入Kafka主题。**



## 6.交易域下单事物事实表

**主要任务：**从Kafka读取订单预处理表数据，筛选下单明细数据，写入Kafka对应主题。

**思路分析：**

* **实现步骤：**
  1. 从Kafka dwd_trade_order_pre_process主题读取订单预处理数据；
  2. 筛选下单明细数据：新增数据，即订单表操作类型为insert的数据即为订单明细数据；
  3. 写入Kafka下单明细主题。



## 7.交易域取消订单事物事实表

**主要任务：**从Kafka读取订单预处理表，筛选取消订单明细数据，写入Kafka对应主题。

**思路分析：**

* **实现步骤：**
  1. 从Kafka dwd_trade_order_pre_process主题读取订单预处理数据；
  2. 筛选取消订单明细数据：保留修改了order_status字段且修改后该字段值为“1003”的数据。
  3. 写入Kafka取消订单主题。



## 8.交易域支付成功事物事实表

**主要任务：**从Kafka topic_db主题筛选支付成功数据、从dwd_trade_order_detail主题中读取订单事实数据、MySQL-LookUp字典表，关联三张表形成支付成功宽表，写入Kafka支付成功主题。

**思路分析：**

* **设置TTL：**订单明细数据是在下单时生成的，经过一系列的处理进入订单明细主题，通常支付操作在下单后 15min 内完成即可，因此，支付明细数据可能比订单明细数据滞后 15min。考虑到可能的乱序问题，ttl 设置为 15min + 5s。
* **获取订单明细数据：**用户必然要先下单才有可能支付成功，因此支付成功明细数据集必然是订单明细数据集的子集。
* **筛选支付表数据：**获取支付类型、回调时间（支付成功时间）、支付成功时间戳。本程序为了去除重复数据，在关联后的宽表中补充了处理时间字段，DWS 层将进行详细介绍。支付成功表是由支付成功数据与订单明细做内连接，而后与字典表做 LookUp Join 得来。这个过程中不会出现回撤数据，<u>关联后表的重复数据来源于订单明细表，所以应按照订单明细表的处理时间字段去重，故支付成功明细表的 row_op_ts 取自订单明细表</u>。
* **构建MySQL-LookUp字典表。**
* **关联上述三张表形成支付成功宽表，写入Kafka支付成功主题：**支付成功业务过程的最细粒度为一个 sku 的支付成功记录，payment_info 表的粒度与最细粒度相同，将其作为主表。



## 9.交易域退单事物事实表

**主要任务：**从Kafka读取业务数据，筛选退单表数据，筛选满足条件的订单表数据，建立MySQL-LookUp字典，关联三张表获得退单明细宽表。

**思路分析：**

* **设置TTL：**用户执行一次退单操作时，order_refund_info 会插入多条数据，同时 order_info 表的**一**条对应数据会发生修改，所以两张表不存在业务上的时间滞后问题，因此仅考虑可能的乱序即可，ttl 设置为 5s。
* **筛选退单表数据：**退单业务过程最细粒度的操作为一个订单中一个 SKU 的退单操作，退单表粒度与最细粒度相同，将其作为**主表**。
* **筛选订单表数据并转化为流。**
* **建立MySQL-LookUp字典表。**
* **关联这几张表获得退单明细宽表，写入Kafka退单明细主题。**



## 10.交易域退款成功事物事实表

**主要任务：**

* 从退款表中提取退款成功数据，并将字典表的dic_name维度退化到表中。
* 从订单表中提取退款成功订单数据。
* 从退单表中提取退款成功的明细数据。

**思路分析：**

* **设置TTL：**一次退款支付操作成功时，refund_payment 表会新增记录，订单表 order_info 和退单表order_refund_info 的对应数据会发生修改，几张表之间不存在业务上的时间滞后。因而，仅考虑可能的数据乱序即可。将 ttl 设置为 5s。
* **建立MySQL-LookUp字典表。**
* **读取退款表数据，筛选退款成功数据：**退款表 refund_payment 的粒度为一个订单中一个 SKU 的退款记录，与退款业务过程的最细粒度相同，将其作为**主表**。
* **读取订单表数据，过滤退款成功订单数据。**
* **筛选退款成功的退单明细数据。**
* **关联四张表并写出到Kafka退款成功主题。**



## 11.工具域优惠劵领取事物事实表

**主要任务：**读取优惠劵领用数据，写入Kafka优惠劵领用主题。

**思路分析：**用户领取优惠劵后，业务数据库的优惠劵领用表会新增一条数据，因此操作类型为insert的数据即为优惠劵领取数据。



## 12.工具域优惠劵使用（下单）事物事实表

**主要任务：**读取优惠劵领用表数据，筛选优惠劵下单数据，写入Kafka优惠劵下单主题。

**思路分析：**

* 执行步骤：
  1. 通过三个条件筛选优惠劵使用（下单）数据。
  2. 建立Upsert-Kafka表，将优惠劵使用（下单）数据写入Kafka优惠劵使用（下单）事实主题。



## 13.工具域优惠劵使用（支付）事物事实表

**主要任务：**读取优惠劵领用表数据，筛选优惠劵支付数据，写入Kafka优惠劵支付主题。

**思路分析：**用户使用优惠券支付时，优惠券领用表的 used_time 字段会更新为支付时间，因此优惠券支付数据应满足两个条件：（1）操作类型为 update；（2）修改了 used_time 字段。使用优惠券支付后，优惠券领用表数据就不会再发生变化，所以在操作类型为 update 的前提下，只要 used_time 不为 null，就可以断定本次操作修改的是 used_time 字段。



## 14.互动域收藏商品事物事实表

**主要任务：**读取收藏数据，写入Kafka主题。

**思路分析：**用户收藏商品时业务数据库的收藏表会插入一条数据，因此筛选操作类型为insert的数据即可。



## 15.互动域评价事物事实表

**主要任务：**建立MySQL-LookUp字典表，读取评论表数据，关联字典表以获取评价（好评、中评、差评、自动），将结果写入Kafka评价主题。

**思路分析：**

* **设置TTL：**与字典表关联时 ttl 的设置主要是考虑到从外部介质查询维度数据的时间，此处设置为 5s。
* **筛选评论数据：**用户提交评论时评价表会插入一条数据，筛选操作类型为 insert 的数据即可。
* **建立MySQL-LookUp字典表。**
* **关联两张表。**
* **写入Kafka互动域评论事实主题。**



## 16.用户域用户注册事物事实表

**主要任务：**读取用户表数据，获取注册时间，将用户注册信息写入Kafka用户注册主题。

**思路分析：**用户注册时会在用户表中插入一条数据，筛选操作类型为insert的数据即可。
