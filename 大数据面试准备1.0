---
title :大数据面试准备

---

# 一. Hadoop

## 1. MapReduce过程一共有几次排序

* 一共有三次排序
* 当环形缓冲区数据达到阈值时，在**刷写磁盘之前**，先**对环形缓冲区进行分区排序（快排）**，将排好序的数据刷写到磁盘。
* 在**map任务完成之前**，经过多次溢写磁盘，产生了多个小文件。将相同分区的小文件合并（归并）成一个大文件，作为最终的map任务输出。
* 在**reduce任务阶段**，需要将多个map任务的输出拷贝到reducetask中合并，**由于分区内有序，只需做一次归并排序**。



## 2. Yarn的任务提交流程

* 首先客户端提交任务到ResourceManager上，同时客户端会向ResourceManager申请一个application，然后ResourceManager会告诉客户端资源（jar包，配置文件）提交的路径。然后客户端就会将资源提交到对应的路径上。
* 提交完毕后，会向ResourceManager申请AppcationMaster。ResourceManager会将用户的请求初始化成一个task，放入调度队列中，接着就会有NodeManager领取task任务，并且创建container容器和启动ApplicationMaster。下载客户端提交的资源到本地。
* 然后ApplicationMaster会向ResourceManager申请运行MapTask的资源，假设有三个切片，ResourceManager就会将运行maptask任务分配给三个NodeManager， 这三个NodeManager分别领取任务并创建容器；ApplicationMaster向这三个NodeManager发送程序启动脚本，分别启动maptask；
* ApplicationMaster等待所有maptask运行完毕后，再次向ResourceManager申请容器，运行reducetask。
* 程序运行完毕后，ApplicationMaster会向ResourceManager申请注销自己。



## 3. MapReduce整个流程

* **Map阶段：**首先通过InputFormat将输入目录下的文件进行<u>逻辑切片</u>，默认大小等于block大小，并且每一个切片由一个MapTask来处理，同时将切片中的数据解析成<key, value>的键值对，k表示偏移量，v表示一行的内容；紧接着调用Mapper类中的map方法。将每一行内容进行处理，解析为<k, v>的键值对，在WrodCount案例中，k表示单词，v表示数字1。
* **Shuffle阶段：**
  * **Map端Shuffle：**将map后的<k, v>写入环形缓冲区**【默认100M】**，**一半写元数据信息**（key的起始位置，value的起始位置，value的长度，partition号），**一半写<k, v>数据**，等达到80%的时候，就要进行spill溢写操作。==溢写之前==需要对key按照分区进行==快速排序==【分区算法默认是HashPatitioner，分区号是根据key的hashcode对reduce task个数取模得到的。这时候有一个优化方法可选，==conbiner预聚合操作==，将有相同key的value合并起来，减少溢写到磁盘的数据量，只能用来累加，最大值使用，不能用于求平均值。】；然后溢写到文件中。经过多次溢写操作产生了许多临时文件，在Map阶段结束后，==将临时文件按分区合并（merge归并排序）为一个大文件，最终每个MapTask产生一个大文件==。
  * **Reduce端Shuffle：**reduce会==拉取copy==同一分区的各个MapTask的结果到内存中，如果放不下就会溢写到磁盘上；然后==对内存和磁盘上的数据进行merge归并排序（这样可以将key相同的数据聚到一起）==。
* **Reduce阶段：**key相同的数据会调用一次reduce方法，每次调用产生一个键值对，最后将这些键值对写入到HDFS文件中。



## 4. Yarn的资源调度的三种模型

主要有三种资源调度器：**FIFO(先进先出)**、**Capacity Scheduler(容量调度器)**、**Fair Scheduler(公平调度器)**。

* 先进先出调度器：单队列，先进先出。
* 容量调度器：多队列，每个队列采用先进先出的策略。每个队列可以设置最低的资源保证和资源上限。如果一个队列有资源剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列。（使用深度优先算法，选择选择资源占用率最低的队列分配资源）
* 公平调度器：多队列，保证每个任务公平享有队列资源。



# 二.Spark

## 1. Hadoop和Spark的不同点（为什么Spark更快）

==Shuffle都是需要落盘的，因为在宽依赖中需要将上一阶段的所有分区数据都准备好，才能进入下一阶段，那么如果一直将数据放在内存中，是耗费资源的。==

* **MapReduce需要将计算的中间结果写入磁盘，然后还要读取磁盘，从而导致了频繁的磁盘IO**；而**Spark不需要将计算的中间结果写入磁盘**，这得益于Spark的RDD弹性分布式数据集和DAG有向无环图，**中间结果能够以RDD的形式存放在内存中**，大大减少了磁盘IO。
* **MapReduce在Shuffle时需要花费大量时间排序**，而**Spark在Shuffle时如果选择基于hash的计算引擎，或者满足SortShuffle的bypass机制，是不需要排序的**。
* **MapReduce是多进程模型**，每个task会运行在一个独立的JVM进程中，每次启动都需要重新申请资源，消耗了大量的时间；而**Spark是多线程模型**，每个Executor会单独运行在一个JVM进行中，每个task则是运行在executor中的一个线程。

## 2. 简述spark的shuffle过程

Spark的shuffle分为两种实现：HashShuffle（spark1.2以前）和SortShuffle（spark1.2以后）。

* HashShuffle分为**普通机制**和**合并机制**，分为write阶段和read阶段。
  * **write阶段**就是根据key进行分区，开始先将数据写入对应的buffer中，当buffer满了之后就会溢写到磁盘上，这个时候会产生mapper的数量*reducer数量的小文件，会产生大量的磁盘IO。
  * **read阶段就**是reduce去拉取各个maptask产生的同一个分区的数据；
  * **HashShuffle的合并机制**就是让多个mapper共享buffer，这时候落盘的数量等于reducer的数量*core的个数，从而减少落盘的小文件数量，但是当reducer很多的时候依然会产生大量的磁盘小文件。
* SortShuffle分为普通机制和bypass机制。
  * 普通机制：MapTask计算的结果数据会**先写入一个内存数据结构（默认5M）中**，每写一条数据之后，就会判断一下是否达到了阈值，如果达到了阈值，会**先尝试增加内存到当前内存的2倍，如果申请不到才会溢写，溢写的时候先按照key进行分区和排序，然后将数据溢写到磁盘**，最后会将所有的临时磁盘文件合并为一个大的磁盘文件，**同时生成一个索引文件**；然后ReduceTask去Map端拉取数据的时候，首先解析索引文件，根据索引文件再去拉取对应的数据。
  * **bypass机制**：将普通机制的排序过程去掉了，它的触发条件是**当Shuffle MapTask数量小于200（配置参数）并且算子不是聚合类的Shuffle算子**（比如reduceByKey）的时候，**该机制不会进行排序**，极大提高了性能。

## 3. 简述Spark的作业运行流程

* 首先Spark的客户端将作业提交给YARN的ResourceManager，然后ResourceManager会选在合适的NodeManager分配container并启动ApplicationMaster，然后ApplicationMaster启动Driver；
* 紧接着向ResourceManager申请资源启动Executor，Executor进程启动后会向Driver反向注册，全部注册完成后Driver开始执行main函数，当执行到action算子，触发一个job，并根据宽窄依赖开始划分stage，每个stage生成对应的TaskSet，之后将task分发到各个Executor上执行。

## 4. Spark Driver的作用，以及Client模式和Cluster模式的区别

ApplicationMaster用于向资源调度器(ResourceManager)申请执行任务的资源容器(container)；Driver执行Spark任务中的main方法，负责实际代码的执行工作。**ResourceManager(资源)和Driver(计算)之间的解耦合靠的就是ApplicationMaster。**

* Driver主要负责管理整个集群的作业任务调度；Executor是一个JVM进程，专门用于计算的节点。
* ==Client模式下，Driver运行在客户端==；==Cluster模式下，Driver运行在YARN集群==。

## 5.  简述map和mapPartition的区别

* map算子是串行操作，mapPartition算子是以分区为单位的批处理操作。
* map算子主要对数据进行转换和改变，但是数量不能增加或者减少，而mapPartition算子可以增加或者减少数据（传入一个迭代器，返回一个迭代器）。
* map算子性能比mapPartition算子低，但是mapPartition算子会长时间占用内存，可能会导致内存溢出。

## 6. 简述reduceByKey、foldByKey、aggregateByKey、combineByKey的区别

* **reduceByKey**：==没有初始值，分区内和分区间计算规则一样==。
* **foldByKey**：==有初始值，分区内和分区间计算规则一样==。
* **aggregateByKey**：==有初始值，分区内和分区间计算规则可以不一样==。
* **combineByKey**：==没有初始值，分区内和分区间计算规则可以不一样，同时返回值类型可以与输入类型不一致==。

## 7. Spark为什么需要RDD持久化，持久化的方式有哪几种，它们之间的区别是什么？

* RDD实际上是不存储数据的，那么**如果RDD想要重用，就需要重头开始执行一遍**，所以为了提高RDD的重用性，就有了RDD持久化。
* **缓存(persist和cache)**和**检查点(checkpoint)**：缓存不会切断RDD之间的血缘关系，检查点会切断RDD之间的血缘关系。
  * **cache是将数据临时存储在内存中（底层调用persist(memory_only)）**；
  * **persist是将数据临时存储在磁盘中，程序结束就会自动删除临时文件**；
  * **checkpoint是将数据长久保存在磁盘中**；

## 8. 除了RDD，你还了解Spark的其他数据结构吗

算子以外的代码都是在Driver端执行，算子里面的代码都是在Executor端执行。

* 还了解**累加器**和**广播变量**
  * 累加器：分布式共享只写变量。累加器用来把Executor端变量信息聚合到Driver端。在Driver程序中定义的变量，在Executor端的每个Task都会得到这个变量的一份新的副本，每个task更新这些副本的值后，传回Driver端进行合并。
  * 广播变量：分布式共享只读变量。用来高效分发较大的对象。向所有工作节点发送一个较大的只读值，以供一个或多个Spark操作。



# 三.Hive

Hive可以将结构化的数据映射为一张表，并且可以通过SQL语句进行查询分析。本质上是将SQL转换为MapReduce或者SparkTask来进行计算，数据是存储在HDFS上，简单理解来说Hive就是MapReduce的一个客户端工具。

## 1. Hive和传统数据库之间的区别

* **数据量**：Hive支持大规模的数据计算，MySQL的数据量小一些。
* **数据更新快不快**：Hive官方是不建议对数据进行修改的，因为非常慢。MySQL对数据修改的数据比较快。
* **查询快不快**：Hive大多数查询延迟都比较高，MySQL相对低一些，当数据规模很大的时候，Hive可能比MySQL快。

## 2. Hive的内部表和外部表的区别

建表语句中加上了external关键字修饰的是外部表，没加的就是内部表。

* 内部表的数据有Hive自身管理，外部表的数据有HDFS管理；
* 删除内部表的时候，元数据和表数据都会被删除，删除外部表的时候，仅仅会删除元数据，而表数据不会被删除。
* 通常会建立外部表，因为一个表通常要很多个人使用，以免删除了，还可以找到数据，保证了数据的安全。、

## 3. Hive的静态分区表和动态分区表的区别

分区表，也叫分区裁剪，就是分目录，作用是减少全表扫描。==分区字段不能是表中已经存在的字段==。

* **静态分区**：
  * 分区字段的值是在导入数据的时候手动指定的；
  * 导入数据的方式可以是load data方式，也可以是insert into + select方式。
* **动态分区**:
  * 分区字段的值是基于查询结果自动推断出来的，**查询结果的最后一个字段值就为对应的分区字段值**；
  * 导入数据的方式必须是insert into + select方式；
  * 想使用动态分区表必须对Hive进行两个配置：
    * **开启分区功能** hive.exec.dynamic.partition=true；
    * **设置动态分区的模式为非严格模式**，即允许所有分区字段都可以使用动态分区 hive.exec.dynamic.partition.mode=nonstrict。

## 4. 你知道分桶表吗，谈谈分区表和分桶表的区别

分桶表和分区表的作用都是用来减少全表的扫描，分桶标的分桶规则是：根据分桶字段的hash值，对桶的个数进行取余运算，然后得到该数据应该放到哪个桶里面去。

* **创建方式不同**：分区表是partitioned by，分桶表是clustered by；
* **字段要求不同**：分区字段不能是表中存在的字段，分桶字段一定是表中；
* **表现形式不同**：分区表其实是分了目录存放数据，分桶表是将一个文件拆分为很多文件存放。

## 5.Order By和Sort By的区别

**distribute by**：将数据根据by的字段散列到不同的reduce中；

**cluster by**：当distribute by和sort by字段相同的时候，就等价于cluster by，但是排序只能是升序。

* **order by**： 全局排序，只有一个reducer，缺点是当数据规模大的时候，就会需要很长的计算时间。
* **sort by**：分区排序，保证每个reducer内有序，一般结合distribute by来使用。

==在生产环境中，order by用的比较少，容易导致OOM；一般使用distribute by + sort by。==

## 6. collect_list(key)和collects_set(key)函数的区别，突破group by的字段限制

==Hive中有三种复杂数据类型：array, map, struct。==

* **collect_list(key)**：分组后将某一个字段的全部数据以集合的形式展示。

* **collects_set(key)**：分组后将某一个字段的全部数据去重后以集合的形式展示。

* ```mysql
  select username, collect_list(video_name)[0] 
  from table_1 
  group by username
  ```

## 7. Hive小文件过多怎么办

* **为什么会产生小文件**：在生产环境下，一般会**使用insert + select的方式导入数据，这样会启动MR任务，那么reduce有多少就会输出多少个文件**，insert每执行一次就会产生一次文件，有些场景下，数据同步可能每十分钟就会执行一次，这样就会产生很多小文件。
* **为什么要解决小文件问题**：
  * 对于HDFS来说，大量的小文件存在，namenode需要记录的元数据就非常大，占用大量的内存，影响HDFS的性能。
  * 对于Hive来说，每个文件会启动一个maptask来处理，这样也会浪费计算资源。
* **如何解决小文件问题**：
  * Hive自带的concatenate命令合并小文件，只支持recfile和orc存储格式。
  * MR过程中合并小文件：
    * **Map前**：设置inputformat为combinehiveinputformat，会把多个文件作为一个切片输入；
    * **Map后**，Reduce前：Map输出的时候合并小文件，hive.merge.mapfile；
    * **Reduce后**：reduce输出的时候合并小文件，hive.merge.mapredfiles。
  * 直接设将reduce的数量设置少一点。
  * 使用hadoop的archive归档方式。

## 8. Hive on Spark 和 Spark的区别，计算时间上有差异吗？

* **Hive on Spark**：上层操作HSQL，对SQL进行语法解析生产语法树，根据语法树生成逻辑执行计划，然后优化逻辑执行计划；然后生成物理执行计划，优化物理执行计划，最后生成一棵TaskTree（任务树）。依次执行树中的task，并将结果返回。
* **Spark**：只需编写任务的执行流程，将任务划分为TaskSet，然后依次执行。

==时间上Hive on Spark的速度比Spark快，需要执行SQL解析。==

# 四.Flink

主要用于对有界和无界数据进行有状态计算，其中

* 有界数据流就是指离线数据，有明确的开始和结束时间；
* 无界数据流就是指实时数据，源源不断没有界限；
* 有状态计算指的是，在进行当前数据计算的时候，可以使用之前数据计算的结果。

## 1. Flink和SaprkStreaming区别

* 计算速度不同：Flink是真正的实时计算框架，而SparkStreaming是一个准实时微批次的计算框架。
* 架构模型不同：SparkStreaming在运行时的主要角色包括Driver和Executor，而Flink在运行时主要包括JobManager、TaskManager。
* 时间机制不同：SparkStreaming只支持处理时间，而Flink支持的时间语义包括处理时间、事件时间和注入时间，还提供了watermark机制来处理迟到的数据。

## 2. Flink的作业运行流程（基于YARN）

Slot：每一个TaskManager都包含一定数量的slot，指TaskManager具有的并行执行能力（静态概念）。

并行度：TaskManager运行程序的时候实际使用的并行能力（动态概念）。

JobManager：相当于一个集群的Master，是整个集群的协调者，负责接受job。

TaskManager：实际负责执行计算的Worker。

Client：Flink程序提交的客户端，当用户提交一个Flink程序时，会首先创建一个Client。

* 首先Flink的客户端将作业提交给YARN的ResourceManager，然后ResourceManager会分配container，并选择合适的NodeManager启动ApplicationMaster；
* 然后ApplicationMaster启动JobManager，向ResourceManager申请资源启动TaskManager；
* 然后JobManager就可以分配任务给TaskManager执行。

## 3. Connect算子和Union算子的区别，基于时间的合流Join

* **Union算子的两个流类型必须是一样的，而Connect算子的两个流的类型可以不一样**，connect之后内部其实两个流还是独立的，一般还需要使用comap来进行转换。
* **Union算子可以连接多个流，而Connect算子只能连接两个流**。
* **窗口联结（Window Join）**：可以定义时间窗口，并将两条流中共享一个公共键（key）的数据放在窗口中进行配对处理。
* **间隔联结（Interval Join）**：针对一条流的每个数据，开辟出其时间戳前后的一段时间间隔，看这期间是否有来自另一条流的数据匹配。

## 4. Flink的时间语义有哪几种

* **Event Time**：表示事件创建的时间，通常由事件中的时间戳描述。
* **Ingestion Time**：表示数据进入Flink的时间。
* **Processing Time**：表示执行算子的本地系统时间。

## 5. 谈一下对WaterMark的理解

==只考虑事件时间语义，才会发生乱序（到达窗口的事件前后顺序和事件时间先后顺序不一致）。==

* WaterMark是一种特殊的时间戳，作用就是为了让事件时间慢一点，等迟到的数据都到了，才触发窗口计算。
* WaterMark等于直到**当前事件发生的最大事件时间减去设定的延迟时间assignTimestampWithWatermarks**。
* 当WaterMark等于窗口时间的时候，就会触发计算。

## 6. Flink中有几种类型的状态，你知道状态后端吗

主要有两种类型的状态：**算子状态（Operator State）**和**按键分区状态（Keyed State）**

* **算子状态（Operator State）**：作用范围限定为当前的算子任务实例，也就是支队当前并行子任务实例有效。这就意味着对于一个并行子任务，占据了一个“分区”，它所处理的所有数据都会访问到相同的状态，状态对于同一任务是共享的。
  * **列表状态（List State）**：当前并行子任务上所有状态项的集合。
  * **联合状态列表（UnionList State）**：与列表状态的区别在于，算子并行度进行缩放调整时对于状态的分配方式不同（直接广播状态的完整列表）。
  * **广播状态（Broadcast State）**：所有分区的所有数据都会访问到同一个状态，状态就像被“广播”到所有分区一样。
* **按键分区状态（Keyed State）**：状态是根据输入流中定义的键（Key）来维护和访问的，所以只能定义在按键分区流中，也就是keyBy之后才可以使用。（聚合算子必须在keyBy之后才能使用，就是因为聚合的结果是以keyed State的形式保存的）。
  * **值状态（Value State）**：状态中只保留一个值。
  * **列表状态（List State）**：以列表（List）的形式组织起来，ListState<T>接口的类型参数表示列表中的数据类型。
  * **映射状态（Map State）**：把一些键值对（key-value）作为状态整体保存起来，对应的MapState<UK,UV>接口中，就会有UK和UV两个泛型，分别表示key和value的类型。
  * **归约状态（Reduce State）**：对添加进来的所有数据进行归约，将归约聚合之后的值作为状态保存下来。通过传入一个归约函数（ReduceFunction）来实现归约逻辑。
  * **聚合状态（Aggregating State）**：聚合状态也是一个值，用来保存添加进来的所有数据的聚合结果。聚合逻辑是通过传入一个更加一般化的聚合函数（AggregateFunction）来实现的。里边通过一个累加器（Accumulator）来表示状态，所以聚合的状态类型可以跟添加进来的数据类型完全不同。
* **状态生存时间（TTL）**：很多状态会随着时间的推移逐渐增长，如果不加以限制，最终就会导致存储空间的耗尽。状态在内存中的存在时间超出这个值时，就将它清除。失效时间 = 当前时间+TTL。
  * 状态更新类型指定了什么时候更新状态失效时间（默认为OnCreateAndWrite）
    * **OnCreateAndWrite**：表示只有创建状态和更改状态（写操作）是更新失效时间。
    * **OnReadAndWrite**：表示无论读写操作都会更新状态失效时间。
* **状态后端：**对状态进行存储、访问和维护。
  * **MemoryStateBackend**：内存级的状态后端，会将状态作为内存中的对象进行管理，将它们存储在TaskManager的JVM堆上。而将checkpoint存储在JobManager的内存中。
  * **FsSatateBackend**：将checkpoint存到远程的持久化文件系统（FileSystem）上。而对于本地状态，跟MemoryStateBackend一样，也会存在TaskManager的JVM堆上。
  * **RocksDBStateBackend**：将所有状态序列化后，存入本地的RocksDB中存储。

## 7. Flink是如何做容错的？

* Flink实现容错主要靠CheckPoint机制和State机制。
  * CheckPoint负责定时制作分布式快照、对程序中的状态进行备份；
  * State用来存储计算过程的中间状态。
* State和CheckPoint之间的区别：
  * State存储的是**某一个操作的运行的状态或者历史，维护在内存中**。
  * CheckPoint存储的是**某一时刻所有操作的当前状态的快照，存在磁盘中**。

## 8. Flink是如何保证Exactly-once语义的

* 整个端到端的一致性级别取决于所有组件中一致性最弱的组件。
* 端到端的一致性包括：
  * **Source端**：需要外部源可重置偏移量（具有数据重放的功能）；
  * **内部保证**：依赖于CheckPoint；
  * **Sink端**：需要保证从故障恢复时，数据不会重复写入外部系统。
    * **幂等写入**：同一份数据无论写入多少次，只保存一份结果；
    * **事务写入**：WAL(预写日志)和2PC(两阶段提交)
      * **WAL(预写日志)**：把结果数据**先写入log文件中**，然后在**收到checkpoint完成的通知时，一次性写入sink系统**；
      * **2PC(两阶段提交)**：对于每个checkpoint，sink任务会启动一个事务，并将接下来**所有接收的数据添加到事务里；然后将这些数据写入外部sink系统，但不提交它们（这时只是预提交）；当收到checkpoint完成的通知时，它才正式提交事务**，实现结果的真正写入。

## 9. CheckPoint的步骤

使用checkpoint检查点，其实就是所有任务的状态在某个时间点的一份快照；这个时间点，应该是**所有任务都恰好处理完一个相同的输入数据的时候**。

* Flink应用在启动的时候，Flink的JobManager创建CheckPointCoordinator（检查点协调器）；
* CheckPointCoordinator**周期性的向该流应用的所有source算子发送barrier（屏障）**；
* 当某个source算子收到一个barrier时，便暂停数据处理过程，然后将自己的当前状态制作成快照，并**保存到指定的持久化存储（HDFS）中**，最后向CheckPointCoordinator报告自己快照制作情况，同时**向自身所有下游算子广播该barrier**，恢复数据处理。
* 每个算子按照上面这个操作不断制作快照并向下游广播，**直到最后barrier传递到sink算子，快照制作完成**。
* **当CheckPointCoordinator收到所有算子的报告之后，认为该周期的快照制作成功**；否则，如果在规定的时间内没有收到所有算子的报告，则认为本周期快照制作失败。

## 10. CheckPoint和SavePoint的区别

* checkpoint重点是在于自动容错，savepoint重点在于手动备份、恢复暂停作业；
* checkpoint是Flink自动触发，而savepoint是用户主动触发；
* 状态文件的保存：checkpoint一半都会自动删除；savepoint一半都会保留下来，除非用户去做相应的删除操作。

## 11. Flink是如何处理反压的

* Flink内部是基于Producer-Consumer模型来进行消息传递的，Flink的反压设计也是基于这个模型。
* Flink使用了**高效有界的分布式阻塞队列**，就像Java通用的阻塞队列（BlockingQueue）一样。**下游消费者消费变慢，上游就会受到阻塞**。

## 12. Flink CEP用过吗，简单介绍一下

* CEP（复杂事件处理）用来从无界流中得到满足一定规则的复杂事件。
* 首先定义一个匹配模式（begin where next where within），调用Pattern中的方法，然后将匹配模式应用到数据流上，调用CEP.pattern方法，最后检测出符合匹配条件的复杂事件，进行转换处理，输出告警信息。
* **用户行为分析**：如果有用户5秒内连续登录3次，就告警输出该用户。
* **用户刷单告警**：如果用户有连续3次以上的下单退单行为，就告警输出该用户。

# 五.项目

## 1. 数据采集

使用java脚本生成用户行为日志数据（log file）和业务数据（mysql）。

* 用户行为日志数据：使用Flume采集到Kafka集群，最终使用Flume同步到HDFS集群。
* 业务数据：使用MaxWell将增量数据采集到Kafka集群，使用DataX对每日全量数据同步到HDFS上。

## 2.数据仓库构建

根据维度建模理论构建数据仓库，一共分为五层：ODS层、DWD层、DIM层、DWS层和ADS层。

* 离线数仓：离线部分使用Spark作为计算引擎，编写Hive SQL对数据进行转换。最终使用DataX将ADS层的数据同步到Mysql，然后使用superset进行页面展示。
* 实时数仓：实时部分使用Flink作为计算引擎，将DWD层数据存储到Kafka topic，将DIM层数据存储到Hbase并使用Redis作为旁路缓存，减少对Hbase的访问；将DWS层数据存储到ClickHouse，最终将数据使用sugar进行前端展示。

## 3. ER模型和维度模型，星型和雪花型

==第三范式：不能存在传递函数依赖==。（学号->系名->系主任）

* **ER模型**：将复杂的数据抽象为两个概念-实体和关系。实体表示一个对象，关系是指两个实体之间的关系。一般满足三范式。
* **维度模型**：将复杂的业务通过事实和维度两个概念进行呈现。事实通常对应业务过程，而维度通常对应业务过程发生时所处的环境。

* **规范化**是指使用一系列范式设计数据库的过程，其目的是减少数据冗余，增强数据的一致性。

* **反规范化**是指将多张表的数据冗余到一张表，其目的是减少join操作，提高查询性能。

==在设计维度表时，如果对其进行规范化，得到的维度模型称为雪花模型，如果对其进行反规范化，得到的模型称为星型模型。==

雪花模型比较靠近三范式，但无法完全遵守，因为遵循三范式的性能成本太高。

## 4. 明确数据域

==划分数据域的意义时便于数据的管理和应用。==

数据域分为5个：

* **交易域**：加购、下单、取消订单、支付成功、退单、退款成功。
* **流量域**：页面浏览、启动应用、动作、曝光、错误。
* **用户域**：注册、登录。
* **互动域**：收藏、评价。
* **工具域**：优惠劵领取、优惠券使用（下单）、优惠券使用（支付）。

## 5. 构建业务总线矩阵

业务总线矩阵中包含维度模型所需的所有事实（业务过程）以及维度，以及各业务过程与各维度的关系。

**矩阵的行是一个个业务过程，矩阵的列是一个个的维度**，行与列的交点表示业务过程与维度的关系。

## 6. 明确统计指标

* **原子指标**：基于某一业务过程的度量值，是业务定义中不可再拆解的指标，原子指标的核心功能就是对指标的聚合逻辑进行了定义。如订单总额，订单数等。
* **派生指标**：在原子指标的基础上，加上统计周期、业务限定和统计粒度等。如最近7天的订单总额，各省份的订单数。
* **衍生指标**：在一个或多个派生指标的基础上，通过各种逻辑运算复合而成的。如最近三十天的用户留存率，新增用户留存比例。

## 7. ADS层的各种统计指标

* **流量主题**：

  * **各渠道流量统计**：
    * 最近1/7/30日各渠道**访客数**。
    * 最近1/7/30日各渠道**会话平均停留时长**。
    * 最近1/7/30日各渠道**会话平均浏览页面数**。
    * 最近1/7/30日各渠道**会话总数**。
    * 最近1/7/30日各渠道**跳出率**。
  * **路径分析**：
    * 用户在APP或网站中的访问路径。为了**衡量网站优化的效果或营销推广的效果，以及了解用户行为偏好，时常要对访问路径进行分析**。
    * 用户访问路径的可视化通常使用桑基图。

* **用户主题**：

  * **用户变动统计**：

    * 最近1日流失用户数。
    * 最近1日回流用户数。

  * **用户留存率**：

    **留存分析一般包括新增留存和活跃留存分析。**

    * 新增留存分析：分析某天的新增用户中，多少人有后续的活跃行为。
    * 活跃留存分析：分析某天的活跃用户中，有多少有后续的活跃行为。

  * **用户新增活跃统计**：

    * 最近1/7/30日**新增用户数**。
    * 最近1/7/30日**活跃用户数**。

  * **用户行为漏斗分析**：

    漏斗分析是一个数据分析模型，能够科学反应一个业务过程从起点到终点各阶段用户转化情况。由于能将各阶段环节都展示出来，故哪个阶段存在问题能一目了然。

    * 最近1/7/30日首页浏览人数。
    * 最近1/7/30日商品详情页浏览人数。
    * 最近1/7/30日加购人数。
    * 最近1/7/30日下单人数。
    * 最近1/7/30日支付人数。

  * **新增交易用户统计**：

    * 最近1/7/30日新增下单人数。
    * 最近1/7/30日新增支付人数。

* **商品主题**：

  * **最近7/30日各品牌复购率**：
    * 重复购买人数占购买人数比例。
  * **各品牌商品交易统计**：
    * 最近1/7/30日品牌的订单数。
    * 最近1/7/30日品牌的订单人数。
    * 最近1/7/30日品牌的退单数。
    * 最近1/7/30日品牌的退单人数。
  * **各品类商品交易统计**：
    * 最近1/7/30日品类的订单数。
    * 最近1/7/30日品类的订单人数。
    * 最近1/7/30日品类的退单数。
    * 最近1/7/30日品类的退单人数。
  * 各分类商品购物车存量Top10

* **交易主题**：

  * **交易综合统计**：
    * 最近1/7/30日订单总额。
    * 最近1/7/30日订单数。
    * 最近1/7/30日订单人数。
    * 最近1/7/30日退单数。
    * 最近1/7/30日退单人数。
  * **各省份交易统计**：
    * 最近1/7/30日省份订单数。
    * 最近1/7/30日省份订单金额。

* **优惠券主题**：

  * 最近30天发布的优惠券补贴率。

* **活动主题**：

  * 最近30天发布的活动补贴率。



# 六. ClickHouse

## 1. CilckHouse的写入和读取为什么快

* 使用了==列式存储+分区过滤+稀疏索引==。

# 七. 常考SQL题

## 1. 连续问题

如下数据为蚂蚁森林用户领取的减少碳排放量，找出连续3天及以上减少碳排放量在100以上的用户

| id   | dt         | lowcarbon |
| ---- | ---------- | --------- |
| 1001 | 2021-12-12 | 123       |
| 1002 | 2021-12-12 | 45        |
| 1001 | 2021-12-13 | 43        |
| 1001 | 2021-12-14 | 45        |
| 1001 | 2021-12-15 | 23        |
| 1002 | 2021-12-15 | 45        |

```mysql
select id
from (
    select id, dt, date_sub(dt, row_number() over(partition by id order by dt) rk) diff
    from t
    where lowcarbon > 100
) t1
group by id, diff
having count(*) >= 3
```

## 2. 分组问题

数据为电商公司用户访问时间数据，某个用户连续的访问记录如果时间间隔小于60秒，则分为同一个组。

| id   | ts          |
| ---- | ----------- |
| 1001 | 17523641234 |
| 1001 | 17523641256 |
| 1002 | 17523641278 |
| 1001 | 17523641334 |
| 1002 | 17523641434 |

```mysql
select id, ts, sum(if(diff >= 60, 1, 0)) over(partition by id order by ts) groupId
from (
    select id, ts, ts - lag(ts, 1, 0) over(partition by id order by ts) diff
    from t
) t1
```

## 3. 
